# -*- coding: utf-8 -*-
"""notebookbe063741c8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UJsojohuS1-ny0zwMZwv7qUZTCINR_PK
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.compat.v1 import InteractiveSession
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import DenseNet201, Xception, InceptionResNetV2, VGG19, VGG16
#from keras_efficientnets import EfficientNetB2
from tensorflow.keras.models import Model
from sklearn.model_selection import KFold, StratifiedShuffleSplit
from tensorflow.keras import layers
from tensorflow.keras import optimizers
from tensorflow.keras import  callbacks
import numpy as np
import seaborn as sns
from tensorflow.keras.models import load_model
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import roc_auc_score

config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

print('tf version {}'.format(tf.__version__))
if tf.test.is_gpu_available():
    print(tf.test.gpu_device_name())
else:
    print('TF cannot find GPU')

base_dir = "Data_Path"
cnv_dir = os.path.join(base_dir,'CNV')
dme_dir = os.path.join(base_dir,'DME')
drusen_dir = os.path.join(base_dir,'DRUSEN')
normal_dir = os.path.join(base_dir,'NORMAL')

cnv_fnames = [os.path.join(cnv_dir, fname) for fname in os.listdir(cnv_dir)]
dme_fnames = [os.path.join(dme_dir, fname) for fname in os.listdir(dme_dir)]
drusen_fnames = [os.path.join(drusen_dir, fname) for fname in os.listdir(drusen_dir)]
normal_fnames = [os.path.join(normal_dir, fname) for fname in os.listdir(normal_dir)]

img = plt.imread(cnv_fnames[2])
plt.imshow(img)
plt.show()

def creat_dataframe(fnames):

    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], fnames))

    fnames = pd.Series(fnames, name = 'filePath').astype(str)
    labels = pd.Series(labels, name = 'label')

    df = pd.concat([fnames, labels], axis = 1)

    df = df.sample(frac = 1).reset_index(drop= True)

    return df

cnv_df = creat_dataframe(cnv_fnames)
dme_df = creat_dataframe(dme_fnames)
drusen_df = creat_dataframe(drusen_fnames)
normal_df = creat_dataframe(normal_fnames)

a=cnv_df[:4000]
b=dme_df[:4000]
c=drusen_df[:4000]
d=normal_df[:4000]

df=pd.concat([a,b,c,d], axis=0)

df.shape

df.describe()

df.info()

train_datagen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 40,
    width_shift_range = 0.2,
    height_shift_range = 0.2,
    shear_range = 0.20,
    zoom_range = 0.20,
    horizontal_flip = True,
    fill_mode = 'nearest')

val_datagen = ImageDataGenerator(rescale = 1./255)

def creat_model():

    conv_base = Xception(weights = 'imagenet',
                        include_top = False,
                        input_shape = (150,150,3))


    x = conv_base.output
    x = layers.Flatten()(x)
    x = layers.Dense(256, activation='relu')(x)
    x_output = layers.Dense(4, activation='softmax')(x)

    model = Model(inputs = conv_base.input, outputs = x_output)

    model.compile(loss= 'categorical_crossentropy',
              optimizer = optimizers.Adam(learning_rate=2e-5),
              metrics = ['acc'])

    #RMSprop(lr = 2e-5)
    return model

callbacks_list = [
     callbacks.EarlyStopping( monitor = 'acc',
                           patience = 5,),
     callbacks.ModelCheckpoint('SavedNetwork/Xception.h5',
							monitor='val_acc', verbose=1,
							save_best_only=True, mode='max'),
     callbacks.ReduceLROnPlateau( monitor='val_loss',
                               factor = 0.1,
                               patience = 5,),
     callbacks.History()
   ]

def fit_and_evaluate(train_data_generator, val_data_generator):

    model = None
    model = creat_model()
    results = model.fit(train_data_generator,
			    epochs=3,
			    callbacks=callbacks_list,
			    validation_data=val_data_generator)
    print("Val Score: ", model.evaluate(val_data_generator))

    return results

kfold = StratifiedShuffleSplit(n_splits=5, test_size=0.177, random_state=0)

inputs = df.filePath.values
targets = df.label.values
model_history = []

# K-fold Cross Validation
fold_no = 1
for train, test in kfold.split(inputs, targets):

    training_data = df.iloc[train]
    validation_data = df.iloc[test]

    train_data_generator = train_datagen.flow_from_dataframe(training_data,
                               x_col = "filePath", y_col = "label", target_size = (150,150),
                               batch_size = 8,
                               class_mode = "categorical", shuffle = True)
    val_data_generator  = val_datagen.flow_from_dataframe(validation_data,
                            x_col = "filePath", y_col = "label", target_size = (150,150),
                            batch_size = 8,
                            class_mode = "categorical", shuffle = True)


    train_data_generator.reset()
    val_data_generator.reset()
    print('-'*70)
    print(f'Training for fold {fold_no} ...')

  #history = fit_and_evaluate(train_data_generator, val_data_generator)

    keras.backend.clear_session()

    callbacks_list = [
     callbacks.EarlyStopping( monitor = 'acc',
                           patience = 5,),
     callbacks.ModelCheckpoint('./Xception.h5',
                            monitor='val_acc', verbose=1,
                            save_best_only=True, mode='max'),
     callbacks.ReduceLROnPlateau( monitor='val_loss',
                               factor = 0.1,
                               patience = 5,),
     callbacks.History()
   ]

    model = None
    model = creat_model()
    history = model.fit(train_data_generator,
                validation_data=val_data_generator,
                epochs=100,
                callbacks=callbacks_list)
    #print("Val Score: ", model.evaluate(val_data_generator))
    model_history.append(history)

    #print(history.history)
    train_data_generator.reset()
    val_data_generator.reset()

    fold_no = fold_no + 1

pd.DataFrame(model_history[0].history).to_csv("./Xception_1.csv", index = False)
pd.DataFrame(model_history[1].history).to_csv("./Xception_2.csv", index = False)
pd.DataFrame(model_history[2].history).to_csv("./Xception_3.csv", index = False)
pd.DataFrame(model_history[3].history).to_csv("./Xception_4.csv", index = False)
pd.DataFrame(model_history[4].history).to_csv("./Xception_5.csv", index = False)

fig = plt.figure()
figsize=(15,5)
epoch0=range(1,len(model_history[0].history['acc'])+1)
epoch1=range(1,len(model_history[1].history['acc'])+1)
epoch2=range(1,len(model_history[2].history['acc'])+1)
epoch3=range(1,len(model_history[3].history['acc'])+1)
epoch4=range(1,len(model_history[4].history['acc'])+1)
plt.title('Xception ')
plt.plot(epoch0,model_history[0].history['acc'], label='Train Fold 1', color='black')
plt.plot(epoch0,model_history[0].history['val_acc'], label='Val Fold 1', color='black', linestyle = "dashdot")
plt.plot(epoch1,model_history[1].history['acc'], label='Train Fold 2', color='red', )
plt.plot(epoch1,model_history[1].history['val_acc'], label='Val Fold 2', color='red', linestyle = "dashdot")
plt.plot(epoch2,model_history[2].history['acc'], label='Train Fold 3', color='green', )
plt.plot(epoch2,model_history[2].history['val_acc'], label='Val Fold 3', color='green', linestyle = "dashdot")
plt.plot(epoch3,model_history[3].history['acc'], label='Train Fold 4', color='blue', )
plt.plot(epoch3,model_history[3].history['val_acc'], label='Val Fold 4', color='blue', linestyle = "dashdot")
plt.plot(epoch4,model_history[4].history['acc'], label='Train Fold 5', color='orange', )
plt.plot(epoch4,model_history[4].history['val_acc'], label='Val Fold 5', color='orange', linestyle = "dashdot")
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
#plt.savefig('./ResNet152V2.png',bbox_inches='tight', dpi = 600)
plt.show()

fig = plt.figure()
figsize=(15,5)
epoch0=range(1,len(model_history[0].history['acc'])+1)
epoch1=range(1,len(model_history[1].history['acc'])+1)
epoch2=range(1,len(model_history[2].history['acc'])+1)
epoch3=range(1,len(model_history[3].history['acc'])+1)
epoch4=range(1,len(model_history[4].history['acc'])+1)
plt.title('Xception ')
plt.plot(epoch0,model_history[0].history['acc'], label='Train Fold 1', color='black')
plt.plot(epoch0,model_history[0].history['val_acc'], label='Val Fold 1', color='black', linestyle = "solid")
plt.plot(epoch1,model_history[1].history['acc'], label='Train Fold 2', color='red', )
plt.plot(epoch1,model_history[1].history['val_acc'], label='Val Fold 2', color='red', linestyle = "solid")
plt.plot(epoch2,model_history[2].history['acc'], label='Train Fold 3', color='green', )
plt.plot(epoch2,model_history[2].history['val_acc'], label='Val Fold 3', color='green', linestyle = "solid")
plt.plot(epoch3,model_history[3].history['acc'], label='Train Fold 4', color='blue', )
plt.plot(epoch3,model_history[3].history['val_acc'], label='Val Fold 4', color='blue', linestyle = "solid")
plt.plot(epoch4,model_history[4].history['acc'], label='Train Fold 5', color='orange', )
plt.plot(epoch4,model_history[4].history['val_acc'], label='Val Fold 5', color='orange', linestyle = "solid")
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
#plt.savefig('./Xception.png',bbox_inches='tight', dpi = 600)
plt.show()

range(1,len(model_history[3].history['acc'])+1)

pd.DataFrame(model_history[0].history).to_csv("./Xception_1.csv", index = False)
pd.DataFrame(model_history[1].history).to_csv("./Xception_2.csv", index = False)
pd.DataFrame(model_history[2].history).to_csv("./Xception_3.csv", index = False)
pd.DataFrame(model_history[3].history).to_csv("./Xception_4.csv", index = False)
pd.DataFrame(model_history[4].history).to_csv("./Xception_5.csv", index = False)

model_history[0]

fig = plt.figure()
#figsize=(15,5)

plt.title('Xception')
plt.plot(model_history[0].history['loss'], label='Train Fold 1', color='black')
plt.plot(model_history[0].history['val_loss'], label='Val Fold 1', color='black', linestyle = "solid")
plt.plot(model_history[1].history['loss'], label='Train Fold 2', color='red', )
plt.plot(model_history[1].history['val_loss'], label='Val Fold 2', color='red', linestyle = "solid")
plt.plot(model_history[2].history['loss'], label='Train Fold 3', color='green', )
plt.plot(model_history[2].history['val_loss'], label='Val Fold 3', color='green', linestyle = "solid")
plt.plot(model_history[3].history['loss'], label='Train Fold 4', color='blue', )
plt.plot(model_history[3].history['val_loss'], label='Val Fold 4', color='blue', linestyle = "solid")
plt.plot(model_history[4].history['loss'], label='Train Fold 5', color='orange', )
plt.plot(model_history[4].history['val_loss'], label='Val Fold 5', color='orange', linestyle = "solid")
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
#plt.savefig('LCurve/InceptionResNetV2.png',bbox_inches='tight', dpi = 600)
plt.show()

fig = plt.figure()
#figsize=(15,5)

plt.title('Xception')
plt.plot(model_history[0].history['loss'], label='Train Fold 1', color='black')
plt.plot(model_history[0].history['val_loss'], label='Val Fold 1', color='black', linestyle = "dashdot")
plt.plot(model_history[1].history['loss'], label='Train Fold 2', color='red', )
plt.plot(model_history[1].history['val_loss'], label='Val Fold 2', color='red', linestyle = "dashdot")
plt.plot(model_history[2].history['loss'], label='Train Fold 3', color='green', )
plt.plot(model_history[2].history['val_loss'], label='Val Fold 3', color='green', linestyle = "dashdot")
plt.plot(model_history[3].history['loss'], label='Train Fold 4', color='blue', )
plt.plot(model_history[3].history['val_loss'], label='Val Fold 4', color='blue', linestyle = "dashdot")
plt.plot(model_history[4].history['loss'], label='Train Fold 5', color='orange', )
plt.plot(model_history[4].history['val_loss'], label='Val Fold 5', color='orange', linestyle = "dashdot")
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
#plt.savefig('LCurve/InceptionResNetV2.png',bbox_inches='tight', dpi = 600)
plt.show()

model_history[0].history["acc"]

model_history[0].history['val_acc']

model_history[0].history["loss"]

model_history[0].history["val_loss"]

plt.plot(model_history[0].history['loss'])
plt.plot(model_history[0].history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel ('epoch')
plt.legend(['loss','val'], loc='upper right')
plt.show()

test_base_dir = '/kaggle/input/kermany2018/OCT2017 /test'
test_cnv_dir = os.path.join(test_base_dir,'CNV')
test_dme_dir = os.path.join(test_base_dir,'DME')
test_drusen_dir = os.path.join(test_base_dir,'DRUSEN')
test_normal_dir = os.path.join(test_base_dir,'NORMAL')

test_cnv_fnames = [os.path.join(test_cnv_dir, fname) for fname in os.listdir(test_cnv_dir)]
test_dme_fnames = [os.path.join(test_dme_dir, fname) for fname in os.listdir(test_dme_dir)]
test_drusen_fnames = [os.path.join(test_drusen_dir, fname) for fname in os.listdir(test_drusen_dir)]
test_normal_fnames = [os.path.join(test_normal_dir, fname) for fname in os.listdir(test_normal_dir)]

pd.DataFrame(model_history[0].history).to_csv("./Xception.h5", index = False)

test_cnv_df = creat_dataframe(test_cnv_fnames)
test_dme_df = creat_dataframe(test_dme_fnames)
test_drusen_df = creat_dataframe(test_drusen_fnames)
test_normal_df = creat_dataframe(test_normal_fnames)

test_df=pd.concat([test_cnv_df,test_dme_df,test_drusen_df,test_normal_df], axis = 0 )

test_df.describe()

test_df

from keras import models

test_datagen = ImageDataGenerator(rescale = 1./255)

test_generator  = test_datagen.flow_from_dataframe(test_df,
							x_col = "filePath", y_col = "label", target_size = (150,150),
                            batch_size = 8,
							class_mode = "categorical", shuffle = False)

def draw_confusion_matrix(true, preds):
    plt.figure(figsize = (8,8))
    conf_matx = confusion_matrix(true, preds)
    sns.heatmap(conf_matx, annot=True, annot_kws={"size": 12},
                fmt='g', cbar=True, cmap="Blues", linecolor = "black", linewidth = 1,
                xticklabels = ["CNV", "DME", "DRUSEN", "NORMAL"],
                yticklabels = ["CNV", "DME", "DRUSEN", "NORMAL"])
    plt.ylabel('Actual label')
    plt.xlabel('Predicted label')
    plt.title('Xception', size = 12)
    #plt.savefig('ConfMtx/ResNet152V2.png',bbox_inches='tight', dpi = 600)
    plt.show()

test_loss, test_acc = model.evaluate(test_generator)

print('test acc:', test_acc)
print('test loss:', test_loss)

import numpy as np

test_pred = model.predict(test_generator,
                                verbose=1)

test_pred_array = np.argmax(test_pred,axis=1)

# Map the label
labels = (test_generator.class_indices)
labels = dict((v,k) for k,v in labels.items())
predicted_str = [labels[k] for k in test_pred_array]


test_generator.reset()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
test_labels = le.fit_transform(test_df.label)

import os
import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder
from tensorflow.compat.v1 import InteractiveSession
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import roc_auc_score

test_pred_array

print(classification_report(test_labels, test_pred_array,
                            target_names =["CNV", "DME", "DRUSEN", "NORMAL"],
                            digits=4))

draw_confusion_matrix(test_labels, test_pred_array)

auc_w = roc_auc_score(test_labels, test_pred, multi_class='ovr', average='weighted')
print('AUC_W: %.4f' % auc_w)
auc_mac = roc_auc_score(test_labels, test_pred, multi_class='ovr', average='macro')
print('AUC_M: %.4f' % auc_mac)



